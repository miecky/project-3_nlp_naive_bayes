{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Web APIs & Classification\n",
    "\n",
    "## Part 3a - Modeling: Naive-Bayes\n",
    "\n",
    "In this part, the corpus is evaluated using the **Naive-Bayes** model. I used two types of vectorizations, **CountVectorizer** and **TFIDFVectorizer**. Both vectorizers and their hyperparameters were evaluated through **Pipeline** and **GridSearchCV**. \n",
    "\n",
    "An extra section, **3.5 - Understand-Naive-Bayes** is included in this part for educational purpose. This section reproduces the model results manually for the selected decocument in order to understand concept of the **Naive-Bayes** model.  \n",
    "\n",
    "### Result Summary\n",
    "\n",
    ">**Accuracy & Misclassification**\n",
    "\n",
    "|         Metric         | Baseline | CountVectorizer | TFIDFVectorizer |\n",
    "|:----------------------:|:--------:|:---------------:|:---------------:|\n",
    "| Accuracy Train         |   0.52   |      0.996      |      0.999      |\n",
    "| Accuracy Test          |     -    |      0.996      |      0.996      |\n",
    "| MisClassification Test |     -    |        2        |        2        |\n",
    ">**Note:** all misclassified documents can be correctly classified by human by readging through the documents.\n",
    "\n",
    ">**Best Model Parameters**\n",
    "\n",
    "|    Metric    | CountVectorizer | TFIDFVectorizer |\n",
    "|:------------:|:---------------:|:---------------:|\n",
    "| Tokenizer    |     default     |     default     |\n",
    "| Processer    |  Lemmatization  |  Lemmatization  |\n",
    "| min_df       |        2        |        2        |\n",
    "| max_df       |       0.9       |       0.9       |\n",
    "| max_features |       1000      |       1000      |\n",
    "| ngram_range  |      (1, 1)     |      (1, 1)     |\n",
    "| stop_words   |     english     |     english     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Content\n",
    "\n",
    "- [3.0-Import Libraries](#3.0---Import-Libraries)\n",
    "- [3.1-Load Data](#3.1---Load-Data)\n",
    "- [3.2-Model Preparation](#3.2---Model-Preparation)\n",
    "- [3.3-Fit & Run Model](#3.3---Fit-&-Run-Model)\n",
    "- [3.4-Results](#3.4---Results)\n",
    "- [3.5-Understand-Naive-Bayes](#3.4---Understand-Naive-Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_content</th>\n",
       "      <th>title_and_content</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just found out invasive breast cancer level II</td>\n",
       "      <td>I'm alone and bawling. My 10 year old is retur...</td>\n",
       "      <td>Just found out invasive breast cancer level II...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Kickstarter project for a colourful and we...</td>\n",
       "      <td></td>\n",
       "      <td>New Kickstarter project for a colourful and we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I hate cancer.</td>\n",
       "      <td>I don’t have anything interesting to say. Just...</td>\n",
       "      <td>I hate cancer. I don’t have anything interesti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Having a stereotactic biopsy on Friday</td>\n",
       "      <td>This is my first post ever on Reddit. Hope I'm...</td>\n",
       "      <td>Having a stereotactic biopsy on Friday This is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Advice on beast cancer UK</td>\n",
       "      <td>You can write something like my sister is suff...</td>\n",
       "      <td>Advice on beast cancer UK You can write someth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          post_title  \\\n",
       "0     Just found out invasive breast cancer level II   \n",
       "1  New Kickstarter project for a colourful and we...   \n",
       "2                                     I hate cancer.   \n",
       "3             Having a stereotactic biopsy on Friday   \n",
       "4                          Advice on beast cancer UK   \n",
       "\n",
       "                                        post_content  \\\n",
       "0  I'm alone and bawling. My 10 year old is retur...   \n",
       "1                                                      \n",
       "2  I don’t have anything interesting to say. Just...   \n",
       "3  This is my first post ever on Reddit. Hope I'm...   \n",
       "4  You can write something like my sister is suff...   \n",
       "\n",
       "                                   title_and_content  class  \n",
       "0  Just found out invasive breast cancer level II...      0  \n",
       "1  New Kickstarter project for a colourful and we...      0  \n",
       "2  I hate cancer. I don’t have anything interesti...      0  \n",
       "3  Having a stereotactic biopsy on Friday This is...      0  \n",
       "4  Advice on beast cancer UK You can write someth...      0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store -r df_to_preprocess\n",
    "df = df_to_preprocess\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.520933\n",
       "1    0.479067\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base model Accuracy\n",
    "df['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.1 - Set X and y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X and y\n",
    "X = df['post_title']\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.1 - Train/Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.3 - LemmaTokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a class for customized tokenizer incorporating lemmatizer\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        tokenizer = RegexpTokenizer('(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "        return [self.wnl.lemmatize(t) for t in tokenizer.tokenize(doc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Fit & Run Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3.1 - CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Pipeline\n",
    "pipe_cv = Pipeline([('cvec', CountVectorizer(tokenizer=LemmaTokenizer())),\n",
    "                    ('mnb', MultinomialNB())\n",
    "                   ])\n",
    "\n",
    "# Pipeline_parameter CountVectorizer\n",
    "pipe_params_cv = {\n",
    "    'cvec__max_features': [100, 500, 1000],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__ngram_range':[(1,1),(1,2)],\n",
    "    'cvec__min_df': [2, 3, 4],\n",
    "    'cvec__max_df': [.9, .95, .98]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=4)]: Done 324 out of 324 | elapsed:   24.9s finished\n",
      "/Users/kaizhao/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...d0>,\n",
       "        vocabulary=None)), ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'cvec__max_features': [100, 500, 1000], 'cvec__stop_words': [None, 'english'], 'cvec__ngram_range': [(1, 1), (1, 2)], 'cvec__min_df': [2, 3, 4], 'cvec__max_df': [0.9, 0.95, 0.98]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch\n",
    "gs_cv = GridSearchCV(pipe_cv, \n",
    "                     param_grid=pipe_params_cv, \n",
    "                     verbose=1,\n",
    "                     cv=3,\n",
    "                     n_jobs=4\n",
    "                    )\n",
    "gs_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3.2 - TFIDFVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "pipe_tv = Pipeline([('tvec', TfidfVectorizer(tokenizer=LemmaTokenizer())),\n",
    "                    ('mnb', MultinomialNB())\n",
    "                   ])\n",
    "\n",
    "# Pipeline_parameter TFIDFVectorizer\n",
    "pipe_params_tv = {\n",
    "    'tvec__max_features': [100, 500, 1000],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'tvec__ngram_range':[(1,1),(1,2)],\n",
    "    'tvec__min_df': [2, 3, 4],\n",
    "    'tvec__max_df': [.9, .95, .98]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=4)]: Done 324 out of 324 | elapsed:   25.8s finished\n",
      "/Users/kaizhao/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tvec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...se_idf=True, vocabulary=None)), ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'tvec__max_features': [100, 500, 1000], 'tvec__stop_words': [None, 'english'], 'tvec__ngram_range': [(1, 1), (1, 2)], 'tvec__min_df': [2, 3, 4], 'tvec__max_df': [0.9, 0.95, 0.98]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tv = GridSearchCV(pipe_tv, \n",
    "                     param_grid=pipe_params_tv, \n",
    "                     verbose=1,\n",
    "                     cv=3,\n",
    "                     n_jobs=4\n",
    "                    )\n",
    "gs_tv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4.1 - Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_MNB</th>\n",
       "      <th>TV_MNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.996466</td>\n",
       "      <td>0.998587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.995763</td>\n",
       "      <td>0.995763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CV_MNB    TV_MNB\n",
       "train  0.996466  0.998587\n",
       "test   0.995763  0.995763"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Scores\n",
    "nb_cv_train = gs_cv.score(X_train, y_train)\n",
    "nb_cv_test = gs_cv.score(X_test, y_test)\n",
    "nb_tv_train = gs_tv.score(X_train, y_train)\n",
    "nb_tv_test = gs_tv.score(X_test, y_test)\n",
    "\n",
    "pd.DataFrame({'CV_MNB': [nb_cv_train, nb_cv_test], 'TV_MNB': [nb_tv_train, nb_tv_test]}, index=['train','test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4.2 - Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_df': 0.9, 'cvec__max_features': 1000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': 'english'}\n",
      "\n",
      "{'tvec__max_df': 0.9, 'tvec__max_features': 1000, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 1), 'tvec__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "print(gs_cv.best_params_)\n",
    "print()\n",
    "print(gs_tv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4.3 - Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cv = gs_cv.predict(X_test)\n",
    "y_pred_tv = gs_tv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_bc</th>\n",
       "      <th>pred_aq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_bc</th>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_aq</th>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred_bc  pred_aq\n",
       "actual_bc      244        2\n",
       "actual_aq        0      226"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, y_pred_cv), \n",
    "             columns=['pred_bc', 'pred_aq'], \n",
    "             index=['actual_bc', 'actual_aq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_bc</th>\n",
       "      <th>pred_aq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_bc</th>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_aq</th>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred_bc  pred_aq\n",
       "actual_bc      244        2\n",
       "actual_aq        0      226"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, y_pred_tv),\n",
    "             columns=['pred_bc', 'pred_aq'], \n",
    "             index=['actual_bc', 'actual_aq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 - Understand Naive Bayes\n",
    "\n",
    "> For educational purpose, this section preproduces the MNB model results manually in order to understand what is behind the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5.1 - Vectorize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the best model\n",
    "cvec = CountVectorizer(max_df=0.9, \n",
    "                       max_features=1000, \n",
    "                       min_df=2,\n",
    "                       ngram_range=(1, 1), \n",
    "                       stop_words='english',\n",
    "                       tokenizer=LemmaTokenizer()\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaizhao/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# Fit CountVectorizer\n",
    "X_train_cv = cvec.fit_transform(X_train)\n",
    "X_test_cv = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>13th</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>1700ppb</th>\n",
       "      <th>173</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>xinhua</th>\n",
       "      <th>xpost</th>\n",
       "      <th>xw</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yuan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  10  100  12  13th  15  17  1700ppb  173  20  ...  xinhua  xpost  xw  \\\n",
       "0    0   0    0   0     0   0   0        0    0   0  ...       0      0   0   \n",
       "1    0   0    0   0     0   0   0        0    0   0  ...       0      0   0   \n",
       "2    0   0    0   0     0   0   0        0    0   0  ...       0      0   0   \n",
       "3    0   0    0   0     0   0   0        0    0   0  ...       0      0   0   \n",
       "4    0   0    0   0     0   0   0        0    0   0  ...       0      0   0   \n",
       "\n",
       "   year  yes  yesterday  york  young  youtube  yuan  \n",
       "0     0    0          0     0      0        0     0  \n",
       "1     0    0          0     0      0        0     0  \n",
       "2     0    0          0     0      0        0     0  \n",
       "3     0    0          0     0      0        0     0  \n",
       "4     0    0          0     0      0        0     0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for top 5 rows\n",
    "X_train_cv_df = pd.DataFrame(X_cv.toarray(), columns = cvec.get_feature_names())\n",
    "X_train_cv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5.2 - Multinomial Naive Bayes Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Estimator\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for training data is 0.9964664310954063\n",
      "The accuracy for testing data is 0.9957627118644068\n"
     ]
    }
   ],
   "source": [
    "# Model Test Scores\n",
    "print(f'The accuracy for training data is {mnb.score(X_train_cv, y_train)}')\n",
    "print(f'The accuracy for testing data is {mnb.score(X_test_cv, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict y using X_test\n",
    "y_pred = mnb.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>post_title</th>\n",
       "      <th>bc_prob</th>\n",
       "      <th>aq_prob</th>\n",
       "      <th>class_pred</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514</td>\n",
       "      <td>With a peak over 300 AQI EPA this weekend in B...</td>\n",
       "      <td>7.485148e-03</td>\n",
       "      <td>0.992515</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1642</td>\n",
       "      <td>A Beijing artist wore a face mask wedding dres...</td>\n",
       "      <td>2.415901e-06</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>476</td>\n",
       "      <td>Have you been diagnosed with cancer? We need y...</td>\n",
       "      <td>9.999949e-01</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>Is my home air making me sick?</td>\n",
       "      <td>1.342636e-05</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>639</td>\n",
       "      <td>29/M lump in breast</td>\n",
       "      <td>9.999955e-01</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1088</td>\n",
       "      <td>Question about Air Quality Index</td>\n",
       "      <td>2.192041e-05</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1622</td>\n",
       "      <td>Fewer children visited ER for asthma problems ...</td>\n",
       "      <td>1.327595e-06</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1100</td>\n",
       "      <td>China Renewable Energy Growth Soars &amp;amp; Coal...</td>\n",
       "      <td>5.570501e-06</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1200</td>\n",
       "      <td>A Chinese company is offering free training fo...</td>\n",
       "      <td>2.480461e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>397</td>\n",
       "      <td>Rare phyllodes tumour</td>\n",
       "      <td>8.768979e-01</td>\n",
       "      <td>0.123102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1458</td>\n",
       "      <td>Fire Continues to smoulder at Parkersburg, WVa...</td>\n",
       "      <td>5.897103e-05</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1265</td>\n",
       "      <td>Sydney under blanket of smoke as hazard reduct...</td>\n",
       "      <td>1.599157e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1150</td>\n",
       "      <td>High CO2 Levels</td>\n",
       "      <td>3.963289e-03</td>\n",
       "      <td>0.996037</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                         post_title       bc_prob  \\\n",
       "0    1514  With a peak over 300 AQI EPA this weekend in B...  7.485148e-03   \n",
       "1    1642  A Beijing artist wore a face mask wedding dres...  2.415901e-06   \n",
       "2     476  Have you been diagnosed with cancer? We need y...  9.999949e-01   \n",
       "3    1007                     Is my home air making me sick?  1.342636e-05   \n",
       "4     639                                29/M lump in breast  9.999955e-01   \n",
       "5    1088                   Question about Air Quality Index  2.192041e-05   \n",
       "6    1622  Fewer children visited ER for asthma problems ...  1.327595e-06   \n",
       "7    1100  China Renewable Energy Growth Soars &amp; Coal...  5.570501e-06   \n",
       "8    1200  A Chinese company is offering free training fo...  2.480461e-07   \n",
       "9     397                              Rare phyllodes tumour  8.768979e-01   \n",
       "10   1458  Fire Continues to smoulder at Parkersburg, WVa...  5.897103e-05   \n",
       "11   1265  Sydney under blanket of smoke as hazard reduct...  1.599157e-09   \n",
       "12   1150                                    High CO2 Levels  3.963289e-03   \n",
       "\n",
       "     aq_prob  class_pred  class  \n",
       "0   0.992515           1      1  \n",
       "1   0.999998           1      1  \n",
       "2   0.000005           0      0  \n",
       "3   0.999987           1      1  \n",
       "4   0.000005           0      0  \n",
       "5   0.999978           1      1  \n",
       "6   0.999999           1      1  \n",
       "7   0.999994           1      1  \n",
       "8   1.000000           1      1  \n",
       "9   0.123102           0      0  \n",
       "10  0.999941           1      1  \n",
       "11  1.000000           1      1  \n",
       "12  0.996037           1      1  "
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize Output Results\n",
    "df_y_pred = pd.DataFrame(y_pred, columns=['class_pred'])\n",
    "df_y_test = pd.DataFrame(y_test).reset_index(drop=True)\n",
    "df_X_test = pd.DataFrame(X_test).reset_index(drop=False)\n",
    "df_y_prob = pd.DataFrame(mnb.predict_proba(X_test_cv), columns=['bc_prob','aq_prob'])\n",
    "df_y = pd.concat([df_X_test, df_y_prob, df_y_pred, df_y_test], axis=1)\n",
    "df_y.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>post_title</th>\n",
       "      <th>bc_prob</th>\n",
       "      <th>aq_prob</th>\n",
       "      <th>class_pred</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>691</td>\n",
       "      <td>Board Members You Night Events New Orleans Lou...</td>\n",
       "      <td>0.382495</td>\n",
       "      <td>0.617505</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>725</td>\n",
       "      <td>Axillary web syndrome anyone??</td>\n",
       "      <td>0.202809</td>\n",
       "      <td>0.797191</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                         post_title   bc_prob  \\\n",
       "306    691  Board Members You Night Events New Orleans Lou...  0.382495   \n",
       "354    725                     Axillary web syndrome anyone??  0.202809   \n",
       "\n",
       "      aq_prob  class_pred  class  \n",
       "306  0.617505           1      0  \n",
       "354  0.797191           1      0  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Misclassfied Documents\n",
    "misclassify = df_y['class_pred'] != df_y['class'] # when predicted class is not the same as the actuall class\n",
    "df_y = df_y[misclassify]\n",
    "df_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All misclassfied items can be correctly classfied by human by reading through through the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5.3 - Reproduce Model Results**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>prio_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bc_prob</th>\n",
       "      <td>737.0</td>\n",
       "      <td>0.520848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aq_prob</th>\n",
       "      <td>678.0</td>\n",
       "      <td>0.479152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  prio_prob\n",
       "bc_prob  737.0   0.520848\n",
       "aq_prob  678.0   0.479152"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prior Probability of BC and AQ (from Training Data)\n",
    "prio_p_class = pd.DataFrame(mnb.class_count_, columns=['count'], index=['bc_prob','aq_prob'])\n",
    "prio_p_class['prio_prob'] = prio_p_class['count']/prio_p_class['count'].sum()\n",
    "prio_p_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high', 'co2', 'levels']"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick index 12 for feature analysis\n",
    "select_title = df_y.iloc[12, 1].lower().split(' ')\n",
    "select_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature probability\n",
    "feature_prob = pd.DataFrame(np.exp(mnb.feature_log_prob_), columns=cvec.get_feature_names()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>co2</th>\n",
       "      <th>levels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bc_prob</th>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aq_prob</th>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.002537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             high       co2    levels\n",
       "bc_prob  0.001292  0.000258  0.000258\n",
       "aq_prob  0.005821  0.006269  0.002537"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract feature probability for selected features\n",
    "feat_prob_select = pd.DataFrame([feature_prob.loc[select_title, 0], feature_prob.loc[select_title, 1]],\n",
    "                                index=['bc_prob','aq_prob'])\n",
    "feat_prob_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>co2</th>\n",
       "      <th>levels</th>\n",
       "      <th>prio_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bc_prob</th>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.520848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aq_prob</th>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.479152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             high       co2    levels  prio_prob\n",
       "bc_prob  0.001292  0.000258  0.000258   0.520848\n",
       "aq_prob  0.005821  0.006269  0.002537   0.479152"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add class prio probability to the df\n",
    "mnb_prob = pd.concat([feat_prob_select, prio_p_class], axis=1)\n",
    "mnb_prob.drop(columns='count', inplace=True) # drop column 'count'\n",
    "mnb_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>co2</th>\n",
       "      <th>levels</th>\n",
       "      <th>prio_prob</th>\n",
       "      <th>p_high_co2_levels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bc_prob</th>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.520848</td>\n",
       "      <td>4.493121e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aq_prob</th>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.479152</td>\n",
       "      <td>4.436206e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             high       co2    levels  prio_prob  p_high_co2_levels\n",
       "bc_prob  0.001292  0.000258  0.000258   0.520848       4.493121e-11\n",
       "aq_prob  0.005821  0.006269  0.002537   0.479152       4.436206e-08"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate P('high') * P('co2') * P(levels) * P(Class)\n",
    "mnb_prob['p_high_co2_levels'] = mnb_prob.product(axis=1)\n",
    "mnb_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>co2</th>\n",
       "      <th>levels</th>\n",
       "      <th>prio_prob</th>\n",
       "      <th>p_high_co2_levels</th>\n",
       "      <th>p_high_co2_levels_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bc_prob</th>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.520848</td>\n",
       "      <td>4.493121e-11</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aq_prob</th>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.479152</td>\n",
       "      <td>4.436206e-08</td>\n",
       "      <td>0.998988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             high       co2    levels  prio_prob  p_high_co2_levels  \\\n",
       "bc_prob  0.001292  0.000258  0.000258   0.520848       4.493121e-11   \n",
       "aq_prob  0.005821  0.006269  0.002537   0.479152       4.436206e-08   \n",
       "\n",
       "         p_high_co2_levels_norm  \n",
       "bc_prob                0.001012  \n",
       "aq_prob                0.998988  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize p_high_co2_levels\n",
    "mnb_prob['p_high_co2_levels_norm'] = mnb_prob['p_high_co2_levels']/mnb_prob['p_high_co2_levels'].sum()\n",
    "mnb_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.4 Result Comparison\n",
    "\n",
    "> Results Match!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>co2</th>\n",
       "      <th>levels</th>\n",
       "      <th>prio_prob</th>\n",
       "      <th>p_high_co2_levels</th>\n",
       "      <th>p_high_co2_levels_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bc_prob</th>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.520848</td>\n",
       "      <td>4.493121e-11</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aq_prob</th>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.479152</td>\n",
       "      <td>4.436206e-08</td>\n",
       "      <td>0.998988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             high       co2    levels  prio_prob  p_high_co2_levels  \\\n",
       "bc_prob  0.001292  0.000258  0.000258   0.520848       4.493121e-11   \n",
       "aq_prob  0.005821  0.006269  0.002537   0.479152       4.436206e-08   \n",
       "\n",
       "         p_high_co2_levels_norm  \n",
       "bc_prob                0.001012  \n",
       "aq_prob                0.998988  "
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                    1150\n",
       "post_title    High CO2 Levels\n",
       "bc_prob            0.00101181\n",
       "aq_prob              0.998988\n",
       "class_pred                  1\n",
       "class                       1\n",
       "Name: 12, dtype: object"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.iloc[12]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
